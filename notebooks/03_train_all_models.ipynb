{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b4ec88",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b5b0493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Set memory optimization and check GPU\n",
    "import torch\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c473e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "✓ All dependencies installed\n",
      "✓ CPU cores available: 12\n",
      "✓ Threading support enabled\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q pandas numpy scipy pyarrow matplotlib seaborn scikit-learn statsmodels tqdm joblib ipykernel torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import threading\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(f\"✓ All dependencies installed\")\n",
    "print(f\"✓ CPU cores available: {cpu_count()}\")\n",
    "print(f\"✓ Threading support enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba99a7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: ..\n",
      "Models directory: ../model_weights\n",
      "Results directory: ../results\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "BASE_DIR = '..'\n",
    "\n",
    "# Create output directories\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'model_weights')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "\n",
    "for d in [MODELS_DIR, RESULTS_DIR, DATA_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4449c",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00c9d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/raw...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading LOBSTER files: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 269748 events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(raw_dir, ticker='AMZN'):\n",
    "    \"\"\"\n",
    "    Load raw LOBSTER data and apply basic preprocessing.\n",
    "    Returns preprocessed DataFrame with datetime and normalized prices.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "\n",
    "    msg_files = sorted(glob.glob(os.path.join(raw_dir, '*message*.csv')))\n",
    "    all_dfs = []\n",
    "\n",
    "    for msg_file in tqdm(msg_files, desc='Loading LOBSTER files'):\n",
    "        # Parse filename\n",
    "        filename = os.path.basename(msg_file)\n",
    "        parts = filename.split('_')\n",
    "        date = parts[1]\n",
    "\n",
    "        # Load message and orderbook\n",
    "        df_msg = pd.read_csv(msg_file, header=None,\n",
    "                            names=['time', 'event_type', 'order_id', 'size', 'price', 'direction'])\n",
    "\n",
    "        ob_file = msg_file.replace('message', 'orderbook')\n",
    "        if not os.path.exists(ob_file):\n",
    "            print(f\"Warning: Orderbook file missing for {msg_file}\")\n",
    "            continue\n",
    "\n",
    "        level = 10\n",
    "        cols = []\n",
    "        for i in range(1, level+1):\n",
    "            cols.extend([f'ask_price_{i}', f'ask_size_{i}', f'bid_price_{i}', f'bid_size_{i}'])\n",
    "\n",
    "        df_ob = pd.read_csv(ob_file, header=None, names=cols)\n",
    "\n",
    "        # Merge\n",
    "        if len(df_msg) != len(df_ob):\n",
    "            print(f\"Length mismatch for {date}: {len(df_msg)} vs {len(df_ob)}, skipping\")\n",
    "            continue\n",
    "\n",
    "        df = pd.concat([df_msg, df_ob], axis=1)\n",
    "\n",
    "        # Price normalization (LOBSTER scale is 10,000)\n",
    "        price_cols = [c for c in df.columns if 'price' in c]\n",
    "        df[price_cols] = df[price_cols] / 10000.0\n",
    "\n",
    "        # Time filtering (09:30:00 = 34200, 16:00:00 = 57600)\n",
    "        df = df[(df['time'] >= 34200) & (df['time'] <= 57600)].copy()\n",
    "\n",
    "        # Drop crossed markets\n",
    "        df = df[df['bid_price_1'] < df['ask_price_1']]\n",
    "\n",
    "        # Add datetime\n",
    "        base_date = pd.to_datetime(date)\n",
    "        df['datetime'] = base_date + pd.to_timedelta(df['time'], unit='s')\n",
    "\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    if not all_dfs:\n",
    "        raise ValueError(f\"No valid data files found in {raw_dir}\")\n",
    "\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Check if we have raw data\n",
    "raw_dir = os.path.join(DATA_DIR, 'raw')\n",
    "if os.path.exists(raw_dir) and len(os.listdir(raw_dir)) > 0:\n",
    "    print(f\"Loading data from {raw_dir}...\")\n",
    "    df = load_and_preprocess_data(raw_dir)\n",
    "    print(f\"Loaded {len(df)} events\")\n",
    "else:\n",
    "    print(f\"Raw data directory {raw_dir} not found or empty.\")\n",
    "    print(\"Please upload LOBSTER CSV files to data/raw/ directory.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e87896",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d7fd40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing OFI...\n",
      "Computing microstructure features...\n",
      "Generating labels...\n",
      "✓ Features shape: (269648, 36)\n",
      "✓ Regression labels shape: (269648, 4)\n",
      "✓ Classification labels shape: (269648, 4)\n",
      "Feature names (36): ['ofi_1', 'ofi_cumul_1', 'ofi_2', 'ofi_cumul_2', 'ofi_3', 'ofi_cumul_3', 'ofi_4', 'ofi_cumul_4', 'ofi_5', 'ofi_cumul_5']...\n"
     ]
    }
   ],
   "source": [
    "def compute_ofi(df, max_level=5):\n",
    "    \"\"\"Compute single-level and multi-level OFI.\"\"\"\n",
    "    result = {}\n",
    "    cumul = np.zeros(len(df), dtype=np.float64)\n",
    "\n",
    "    for lvl in range(1, max_level + 1):\n",
    "        bp = df[f\"bid_price_{lvl}\"].values\n",
    "        bs = df[f\"bid_size_{lvl}\"].values\n",
    "        ap = df[f\"ask_price_{lvl}\"].values\n",
    "        as_ = df[f\"ask_size_{lvl}\"].values\n",
    "\n",
    "        n = len(df)\n",
    "        ofi = np.zeros(n, dtype=np.float64)\n",
    "\n",
    "        for t in range(1, n):\n",
    "            delta_bid = bs[t] if bp[t] == bp[t-1] else (bs[t] if bp[t] > bp[t-1] else -bs[t-1])\n",
    "            delta_ask = as_[t] if ap[t] == ap[t-1] else (-as_[t] if ap[t] < ap[t-1] else as_[t-1])\n",
    "            ofi[t] = delta_bid - delta_ask\n",
    "\n",
    "        result[f\"ofi_{lvl}\"] = ofi\n",
    "        cumul = cumul + ofi\n",
    "        result[f\"ofi_cumul_{lvl}\"] = cumul.copy()\n",
    "\n",
    "    return pd.DataFrame(result, index=df.index)\n",
    "\n",
    "def compute_microstructure(df, max_level=5):\n",
    "    \"\"\"Compute microstructure features.\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    features['mid_price'] = (df['ask_price_1'] + df['bid_price_1']) / 2.0\n",
    "    features['spread'] = df['ask_price_1'] - df['bid_price_1']\n",
    "\n",
    "    total = df['bid_size_1'] + df['ask_size_1']\n",
    "    features['volume_imbalance'] = (df['bid_size_1'] - df['ask_size_1']) / total.replace(0, np.nan)\n",
    "    features['volume_imbalance'] = features['volume_imbalance'].fillna(0.0)\n",
    "\n",
    "    bid_depth = sum(df[f'bid_size_{i}'] for i in range(1, max_level + 1))\n",
    "    ask_depth = sum(df[f'ask_size_{i}'] for i in range(1, max_level + 1))\n",
    "    features['bid_depth'] = bid_depth\n",
    "    features['ask_depth'] = ask_depth\n",
    "    features['total_depth'] = bid_depth + ask_depth\n",
    "\n",
    "    return pd.DataFrame(features, index=df.index)\n",
    "\n",
    "def make_labels(df, horizons=[10, 20, 50, 100], alpha=0.5):\n",
    "    \"\"\"Generate regression and 3-class classification labels.\"\"\"\n",
    "    m = (df['ask_price_1'].values + df['bid_price_1'].values) / 2.0\n",
    "\n",
    "    # Regression\n",
    "    reg_labels = {}\n",
    "    for k in horizons:\n",
    "        delta = np.full_like(m, np.nan)\n",
    "        if k < len(m):\n",
    "            delta[:len(m)-k] = m[k:] - m[:len(m)-k]\n",
    "        reg_labels[f'delta_mid_{k}'] = delta\n",
    "\n",
    "    # Classification (3-class: DOWN=0, STAT=1, UP=2)\n",
    "    cls_labels = {}\n",
    "    for k in horizons:\n",
    "        future_m = np.full_like(m, np.nan)\n",
    "        if k < len(m):\n",
    "            # Smooth with k-event moving average\n",
    "            cumsum = np.cumsum(m)\n",
    "            # The original line caused a ValueError due to shape mismatch:\n",
    "            # future_m[:len(m)-k] = (cumsum[k:] - np.concatenate([[0], cumsum[:-k]])) / k\n",
    "            # Corrected to compute the k-event moving average for future mid-prices:\n",
    "            future_m[:len(m)-k] = (cumsum[k:] - cumsum[:-k]) / k\n",
    "\n",
    "        pct_change = (future_m - m) / m\n",
    "        valid = pct_change[~np.isnan(pct_change)]\n",
    "        sigma = np.std(valid)\n",
    "        threshold = alpha * sigma\n",
    "\n",
    "        labels = np.full(len(m), np.nan)\n",
    "        labels[pct_change > threshold] = 2   # UP\n",
    "        labels[pct_change < -threshold] = 0  # DOWN\n",
    "        mask = (~np.isnan(pct_change)) & np.isnan(labels)\n",
    "        labels[mask] = 1  # STATIONARY\n",
    "\n",
    "        cls_labels[f'label_{k}'] = labels\n",
    "\n",
    "    reg_df = pd.DataFrame(reg_labels, index=df.index)\n",
    "    cls_df = pd.DataFrame(cls_labels, index=df.index)\n",
    "    return reg_df, cls_df\n",
    "\n",
    "if df is not None:\n",
    "    print(\"Computing OFI...\")\n",
    "    ofi_df = compute_ofi(df)\n",
    "\n",
    "    print(\"Computing microstructure features...\")\n",
    "    micro_df = compute_microstructure(df)\n",
    "\n",
    "    print(\"Generating labels...\")\n",
    "    horizons = [10, 20, 50, 100]\n",
    "    y_reg, y_cls = make_labels(df, horizons=horizons)\n",
    "\n",
    "    # Combine features\n",
    "    lob_cols = []\n",
    "    for lvl in range(1, 6):\n",
    "        lob_cols.extend([f'ask_price_{lvl}', f'ask_size_{lvl}', f'bid_price_{lvl}', f'bid_size_{lvl}'])\n",
    "\n",
    "    X = pd.concat([ofi_df, micro_df, df[lob_cols]], axis=1)\n",
    "    feature_names = list(X.columns)\n",
    "\n",
    "    # Remove tail rows with NaN labels\n",
    "    max_horizon = max(horizons)\n",
    "    valid_end = len(df) - max_horizon\n",
    "\n",
    "    X_data = X.values[:valid_end].astype(np.float32)\n",
    "    y_reg_data = y_reg.values[:valid_end].astype(np.float32)\n",
    "    y_cls_data = y_cls.values[:valid_end].astype(np.float32)\n",
    "\n",
    "    print(f\"✓ Features shape: {X_data.shape}\")\n",
    "    print(f\"✓ Regression labels shape: {y_reg_data.shape}\")\n",
    "    print(f\"✓ Classification labels shape: {y_cls_data.shape}\")\n",
    "    print(f\"Feature names ({len(feature_names)}): {feature_names[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb1145",
   "metadata": {},
   "source": [
    "## 4. Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee371933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 161788 | Val: 53930 | Test: 53930\n",
      "Features: 36\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Temporal split (no future leakage)\n",
    "    train_frac, val_frac = 0.6, 0.2\n",
    "\n",
    "    n = len(X_data)\n",
    "    t1 = int(n * train_frac)\n",
    "    t2 = int(n * (train_frac + val_frac))\n",
    "\n",
    "    X_train, y_reg_train, y_cls_train = X_data[:t1], y_reg_data[:t1], y_cls_data[:t1]\n",
    "    X_val, y_reg_val, y_cls_val = X_data[t1:t2], y_reg_data[t1:t2], y_cls_data[t1:t2]\n",
    "    X_test, y_reg_test, y_cls_test = X_data[t2:], y_reg_data[t2:], y_cls_data[t2:]\n",
    "\n",
    "    # Normalization (fit on train only)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(f\"Train: {X_train_scaled.shape[0]} | Val: {X_val_scaled.shape[0]} | Test: {X_test_scaled.shape[0]}\")\n",
    "    print(f\"Features: {X_train_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f85eb",
   "metadata": {},
   "source": [
    "## 5. PyTorch Models & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b14cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset classes defined\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset\n",
    "class LOBDataset(Dataset):\n",
    "    def __init__(self, X, y_reg, y_cls, seq_len=100):\n",
    "        self.X = X\n",
    "        self.y_reg = y_reg\n",
    "        self.y_cls = y_cls\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx:idx + self.seq_len]\n",
    "        target_idx = idx + self.seq_len - 1\n",
    "        yr = self.y_reg[target_idx]\n",
    "        yc = self.y_cls[target_idx]\n",
    "\n",
    "        return {\n",
    "            'x': torch.tensor(x, dtype=torch.float32),\n",
    "            'y_reg': torch.tensor(yr, dtype=torch.float32),\n",
    "            'y_cls': torch.tensor(yc, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "class FlatDataset(Dataset):\n",
    "    def __init__(self, X, y_reg, y_cls):\n",
    "        self.X = X\n",
    "        self.y_reg = y_reg\n",
    "        self.y_cls = y_cls\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': torch.tensor(self.X[idx], dtype=torch.float32),\n",
    "            'y_reg': torch.tensor(self.y_reg[idx], dtype=torch.float32),\n",
    "            'y_cls': torch.tensor(self.y_cls[idx], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "print(\"✓ Dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05493134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAttentionSeq2Seq(nn.Module):\n",
    "    \"\"\"Seq2Seq with temporal attention + multi-scale encoder (Custom)\"\"\"\n",
    "    def __init__(self, n_features, n_horizons=4, hidden_size=64, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-scale encoder\n",
    "        self.encoder_fine = nn.LSTM(n_features, hidden_size, 2, batch_first=True, dropout=dropout)\n",
    "        self.encoder_coarse = nn.LSTM(n_features, hidden_size, 1, batch_first=True)\n",
    "        \n",
    "        # Temporal attention\n",
    "        self.attn = BahdanauAttention(hidden_size)\n",
    "        self.decoder = nn.LSTM(hidden_size * 2, hidden_size, 1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(hidden_size, 32), nn.ReLU(), nn.Linear(32, 3))\n",
    "            for _ in range(n_horizons)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc_fine, (h_fine, c_fine) = self.encoder_fine(x)\n",
    "        enc_coarse, (h_coarse, c_coarse) = self.encoder_coarse(x)\n",
    "        context, _ = self.attn(h_fine[-1], enc_fine)\n",
    "        multi_ctx = torch.cat([context, h_coarse[-1]], dim=-1)\n",
    "        dec_in = multi_ctx.unsqueeze(1)\n",
    "        # Use only last layer's hidden state for decoder (decoder has 1 layer, encoder_fine has 2)\n",
    "        dec_out, _ = self.decoder(dec_in, (h_fine[-1:], c_fine[-1:]))\n",
    "        out_h = self.dropout(dec_out[:, -1, :])\n",
    "        out = torch.stack([head(out_h) for head in self.heads], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dd4355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metric computation defined\n"
     ]
    }
   ],
   "source": [
    "# Training utilities\n",
    "def compute_metrics(y_true, y_pred, y_true_cls=None, y_pred_cls=None):\n",
    "    \"\"\"Compute regression and classification metrics.\"\"\"\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Regression\n",
    "    if y_true is not None and y_pred is not None:\n",
    "        mask = ~np.isnan(y_true)\n",
    "        if mask.sum() > 0:\n",
    "            residuals = y_true[mask] - y_pred[mask]\n",
    "            metrics['mse'] = float(np.mean(residuals ** 2))\n",
    "            metrics['rmse'] = float(np.sqrt(metrics['mse']))\n",
    "            metrics['mae'] = float(np.mean(np.abs(residuals)))\n",
    "            ss_res = np.sum(residuals ** 2)\n",
    "            ss_tot = np.sum((y_true[mask] - np.mean(y_true[mask])) ** 2)\n",
    "            metrics['r2'] = float(1.0 - ss_res / max(ss_tot, 1e-12))\n",
    "\n",
    "    # Classification\n",
    "    if y_true_cls is not None and y_pred_cls is not None:\n",
    "        mask = ~np.isnan(y_true_cls)\n",
    "        if mask.sum() > 0:\n",
    "            metrics['accuracy'] = float(accuracy_score(y_true_cls[mask].astype(int), y_pred_cls[mask]))\n",
    "            metrics['f1_macro'] = float(f1_score(y_true_cls[mask].astype(int), y_pred_cls[mask], average='macro', zero_division=0))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "print(\"✓ Metric computation defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1710010",
   "metadata": {},
   "source": [
    "## 6. Model Training & Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18dc03e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING LINEAR MODELS (PARALLELIZED)\n",
      "================================================================================\n",
      "✓ ridge           | R² h10=0.0379 | Saved\n",
      "✓ lasso           | R² h10=0.0104 | Saved\n",
      "✓ ols             | R² h10=0.0371 | Saved\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # ALL 10 MODEL CONFIGURATIONS\n",
    "    model_configs = {\n",
    "        # Linear (parallel: can train all at once)\n",
    "        'ols': {'type': 'linear', 'parallel': True},\n",
    "        'ridge': {'type': 'linear', 'parallel': True, 'alpha': 1.0},\n",
    "        'lasso': {'type': 'linear', 'parallel': True, 'alpha': 0.001},\n",
    "        \n",
    "        # Deep (GPU-friendly, train sequentially to avoid OOM, but parallelize internally)\n",
    "        'mlp': {'type': 'flat', 'epochs': 25, 'batch_size': 1024, 'lr': 1e-3},\n",
    "        'lstm': {'type': 'seq', 'seq_len': 100, 'epochs': 25, 'batch_size': 512, 'lr': 1e-3},\n",
    "        'cnn': {'type': 'seq', 'seq_len': 100, 'epochs': 25, 'batch_size': 512, 'lr': 1e-3},\n",
    "        'deeplob': {'type': 'seq', 'seq_len': 100, 'epochs': 25, 'batch_size': 512, 'lr': 1e-3},\n",
    "        'seq2seq': {'type': 'seq', 'seq_len': 100, 'epochs': 25, 'batch_size': 512, 'lr': 1e-3},\n",
    "        'transformer': {'type': 'seq', 'seq_len': 100, 'epochs': 25, 'batch_size': 512, 'lr': 1e-3},\n",
    "        'temporal_attention': {'type': 'seq', 'seq_len': 100, 'epochs': 25, 'batch_size': 512, 'lr': 1e-3},\n",
    "    }\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    # ===== TRAIN LINEAR MODELS IN PARALLEL =====\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING LINEAR MODELS (PARALLELIZED)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    def train_linear_model(args):\n",
    "        \"\"\"Train a single linear model (OLS, Ridge, or Lasso).\"\"\"\n",
    "        model_name, model_type, X_tr, y_reg_tr, X_te, y_reg_te, horizons, config = args\n",
    "        try:\n",
    "            models_dict = {}\n",
    "            for h_idx, h in enumerate(horizons):\n",
    "                y = y_reg_tr[:, h_idx]\n",
    "                mask = ~np.isnan(y)\n",
    "                X_h = X_tr[mask]\n",
    "                y_h = y[mask]\n",
    "                \n",
    "                if model_name == 'ols':\n",
    "                    X_const = sm.add_constant(X_h)\n",
    "                    model = sm.OLS(y_h, X_const).fit(disp=0)\n",
    "                elif model_name == 'ridge':\n",
    "                    from sklearn.linear_model import Ridge\n",
    "                    model = Ridge(alpha=config.get('alpha', 1.0))\n",
    "                    model.fit(X_h, y_h)\n",
    "                elif model_name == 'lasso':\n",
    "                    from sklearn.linear_model import Lasso\n",
    "                    model = Lasso(alpha=config.get('alpha', 0.001), max_iter=5000)\n",
    "                    model.fit(X_h, y_h)\n",
    "                \n",
    "                models_dict[h] = model\n",
    "            \n",
    "            # Evaluate\n",
    "            preds_test = np.zeros((len(X_te), len(horizons)))\n",
    "            for h_idx, h in enumerate(horizons):\n",
    "                if model_name == 'ols':\n",
    "                    X_const = sm.add_constant(X_te)\n",
    "                    preds_test[:, h_idx] = models_dict[h].predict(X_const)\n",
    "                else:\n",
    "                    preds_test[:, h_idx] = models_dict[h].predict(X_te)\n",
    "            \n",
    "            metrics = {}\n",
    "            for h_idx, h in enumerate(horizons):\n",
    "                m = compute_metrics(y_reg_te[:, h_idx], preds_test[:, h_idx])\n",
    "                for k, v in m.items():\n",
    "                    metrics[f'h{h}_{k}'] = v\n",
    "            \n",
    "            return model_name, models_dict, metrics\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {model_name} failed: {e}\")\n",
    "            return model_name, None, {}\n",
    "    \n",
    "    # Prepare linear model training tasks\n",
    "    linear_tasks = [\n",
    "        ('ols', 'linear', X_train_scaled, y_reg_train, X_test_scaled, y_reg_test, horizons, model_configs['ols']),\n",
    "        ('ridge', 'linear', X_train_scaled, y_reg_train, X_test_scaled, y_reg_test, horizons, model_configs['ridge']),\n",
    "        ('lasso', 'linear', X_train_scaled, y_reg_train, X_test_scaled, y_reg_test, horizons, model_configs['lasso']),\n",
    "    ]\n",
    "    \n",
    "    # Train linear models in parallel\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        linear_futures = {executor.submit(train_linear_model, task): task[0] for task in linear_tasks}\n",
    "        \n",
    "        for future in as_completed(linear_futures):\n",
    "            model_name, models_dict, metrics = future.result()\n",
    "            if models_dict is not None:\n",
    "                all_results[model_name] = metrics\n",
    "                # Save model\n",
    "                save_path = os.path.join(MODELS_DIR, f'{model_name}_models.pkl')\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    pickle.dump(models_dict, f)\n",
    "                print(f\"✓ {model_name:15s} | R² h10={metrics.get('h10_r2', 0):.4f} | Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0815a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING DEEP LEARNING MODELS (MEMORY-OPTIMIZED SEQUENTIAL)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics, model\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# ===== DEFINE ALL 7 DEEP MODELS =====\u001b[39;00m\n\u001b[32m    119\u001b[39m deep_models_def = {\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmlp\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mMLPClassifier\u001b[49m,\n\u001b[32m    121\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m: LSTMClassifier,\n\u001b[32m    122\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m'\u001b[39m: CNNClassifier,\n\u001b[32m    123\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdeeplob\u001b[39m\u001b[33m'\u001b[39m: DeepLOBNet,\n\u001b[32m    124\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mseq2seq\u001b[39m\u001b[33m'\u001b[39m: Seq2SeqAttention,\n\u001b[32m    125\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m'\u001b[39m: TransformerClassifier,\n\u001b[32m    126\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtemporal_attention\u001b[39m\u001b[33m'\u001b[39m: TemporalAttentionSeq2Seq,\n\u001b[32m    127\u001b[39m }\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# ===== TRAIN EACH DEEP MODEL =====\u001b[39;00m\n\u001b[32m    130\u001b[39m deep_models = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # ===== CONFIGURATION: SKIP ALREADY-TRAINED MODELS =====\n",
    "    SKIP_TRAINED_MODELS = True  # Set to False to retrain all models\n",
    "    \n",
    "    # ===== TRAIN DEEP LEARNING MODELS SEQUENTIALLY (GPU memory management) =====\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING DEEP LEARNING MODELS (MEMORY-OPTIMIZED SEQUENTIAL)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    def train_deep_model(model, train_loader, val_loader, test_loader, model_name, cfg, device):\n",
    "        \"\"\"Generic training loop with memory optimization.\"\"\"\n",
    "        model = model.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(model.parameters(), lr=cfg['lr'], weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        max_patience = 5\n",
    "        best_model_state = None\n",
    "        \n",
    "        epochs = cfg['epochs']\n",
    "        for epoch in range(epochs):\n",
    "            # ===== TRAINING =====\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                x = batch['x'].to(device)\n",
    "                y_cls = batch['y_cls'].to(device)\n",
    "                \n",
    "                logits = model(x)\n",
    "                loss = 0\n",
    "                for h_idx in range(logits.shape[1]):\n",
    "                    loss = loss + criterion(logits[:, h_idx, :], y_cls[:, h_idx])\n",
    "                loss = loss / logits.shape[1]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                # Clear cache every 5 batches\n",
    "                if (batch_idx + 1) % 5 == 0:\n",
    "                    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # ===== VALIDATION =====\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    x = batch['x'].to(device)\n",
    "                    y_cls = batch['y_cls'].to(device)\n",
    "                    logits = model(x)\n",
    "                    loss = 0\n",
    "                    for h_idx in range(logits.shape[1]):\n",
    "                        loss = loss + criterion(logits[:, h_idx, :], y_cls[:, h_idx])\n",
    "                    loss = loss / logits.shape[1]\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= max_patience:\n",
    "                    print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % max(1, epochs // 5) == 0:\n",
    "                print(f\"  [{model_name}] Epoch {epoch+1:2d}/{epochs} | train_loss={train_loss:.5f} | val_loss={val_loss:.5f}\")\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(best_model_state)\n",
    "        model.eval()\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        # ===== EVALUATION =====\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x = batch['x'].to(device)\n",
    "                y_cls = batch['y_cls'].to(device)\n",
    "                logits = model(x)\n",
    "                preds = logits.argmax(dim=-1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(y_cls.cpu().numpy())\n",
    "        \n",
    "        all_preds = np.concatenate(all_preds, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        \n",
    "        metrics = {}\n",
    "        for h_idx, h in enumerate(horizons):\n",
    "            m = compute_metrics(None, None, all_labels[:, h_idx], all_preds[:, h_idx])\n",
    "            for k, v in m.items():\n",
    "                metrics[f'h{h}_{k}'] = v\n",
    "        \n",
    "        # Save model\n",
    "        model_path = os.path.join(MODELS_DIR, f'{model_name}_weights.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        return metrics, model\n",
    "    \n",
    "    # ===== DEFINE ALL 7 DEEP MODELS =====\n",
    "    deep_models_def = {\n",
    "        'mlp': MLPClassifier,\n",
    "        'lstm': LSTMClassifier,\n",
    "        'cnn': CNNClassifier,\n",
    "        'deeplob': DeepLOBNet,\n",
    "        'seq2seq': Seq2SeqAttention,\n",
    "        'transformer': TransformerClassifier,\n",
    "        'temporal_attention': TemporalAttentionSeq2Seq,\n",
    "    }\n",
    "    \n",
    "    # ===== TRAIN EACH DEEP MODEL =====\n",
    "    deep_models = {}\n",
    "    deep_model_names = list(deep_models_def.keys())\n",
    "    \n",
    "    for idx, model_name in enumerate(deep_model_names, 1):\n",
    "        # Check if model already trained\n",
    "        model_path = os.path.join(MODELS_DIR, f'{model_name}_weights.pt')\n",
    "        if SKIP_TRAINED_MODELS and os.path.exists(model_path):\n",
    "            print(f\"\\n[{idx}/{len(deep_models_def)}] {model_name.upper()} - SKIPPED (already trained)\")\n",
    "            # Load existing model\n",
    "            model = deep_models_def[model_name](n_features=X_train_scaled.shape[1], n_horizons=len(horizons))\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            deep_models[model_name] = model\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{idx}/{len(deep_models_def)}] Training {model_name.upper()}...\")\n",
    "        \n",
    "        try:\n",
    "            cfg = model_configs[model_name]\n",
    "            \n",
    "            # Create datasets\n",
    "            if cfg['type'] == 'flat':\n",
    "                ds_train = FlatDataset(X_train_scaled, y_reg_train, y_cls_train)\n",
    "                ds_val = FlatDataset(X_val_scaled, y_reg_val, y_cls_val)\n",
    "                ds_test = FlatDataset(X_test_scaled, y_reg_test, y_cls_test)\n",
    "            else:  # seq\n",
    "                ds_train = LOBDataset(X_train_scaled, y_reg_train, y_cls_train, seq_len=cfg['seq_len'])\n",
    "                ds_val = LOBDataset(X_val_scaled, y_reg_val, y_cls_val, seq_len=cfg['seq_len'])\n",
    "                ds_test = LOBDataset(X_test_scaled, y_reg_test, y_cls_test, seq_len=cfg['seq_len'])\n",
    "            \n",
    "            # Create dataloaders with shuffle=True for training\n",
    "            train_loader = DataLoader(ds_train, batch_size=cfg['batch_size'], shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(ds_val, batch_size=cfg['batch_size'], shuffle=False, num_workers=0)\n",
    "            test_loader = DataLoader(ds_test, batch_size=cfg['batch_size'], shuffle=False, num_workers=0)\n",
    "            \n",
    "            # Create model\n",
    "            model = deep_models_def[model_name](n_features=X_train_scaled.shape[1], n_horizons=len(horizons))\n",
    "            \n",
    "            # Train\n",
    "            metrics, model_obj = train_deep_model(model, train_loader, val_loader, test_loader, model_name, cfg, device)\n",
    "            \n",
    "            all_results[model_name] = metrics\n",
    "            deep_models[model_name] = model_obj\n",
    "            \n",
    "            print(f\"✓ {model_name:20s} | Accuracy h10={metrics.get('h10_accuracy', 0):.4f} | F1={metrics.get('h10_f1_macro', 0):.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"✗ {model_name} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279b0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Train LSTM\n",
    "    print(\"\\n[2/3] Training LSTM...\")\n",
    "    try:\n",
    "        cfg = model_configs['lstm']\n",
    "        ds_train = LOBDataset(X_train_scaled, y_reg_train, y_cls_train, seq_len=cfg['seq_len'])\n",
    "        ds_val = LOBDataset(X_val_scaled, y_reg_val, y_cls_val, seq_len=cfg['seq_len'])\n",
    "        ds_test = LOBDataset(X_test_scaled, y_reg_test, y_cls_test, seq_len=cfg['seq_len'])\n",
    "        \n",
    "        train_loader = DataLoader(ds_train, batch_size=cfg['batch_size'], shuffle=False)\n",
    "        val_loader = DataLoader(ds_val, batch_size=cfg['batch_size'], shuffle=False)\n",
    "        test_loader = DataLoader(ds_test, batch_size=cfg['batch_size'], shuffle=False)\n",
    "        \n",
    "        lstm_model = LSTMClassifier(n_features=X_train_scaled.shape[1], n_horizons=len(horizons))\n",
    "        lstm_metrics, lstm_model = train_deep_model(\n",
    "            lstm_model, train_loader, val_loader, test_loader, 'lstm',\n",
    "            epochs=cfg['epochs'], lr=cfg['lr']\n",
    "        )\n",
    "        all_results['lstm'] = lstm_metrics\n",
    "        print(f\"✓ LSTM Accuracy h10={lstm_metrics.get('h10_accuracy', 0):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ LSTM failed: {e}\")\n",
    "    \n",
    "    # Train CNN\n",
    "    print(\"\\n[3/3] Training CNN...\")\n",
    "    try:\n",
    "        cfg = model_configs['cnn']\n",
    "        ds_train = LOBDataset(X_train_scaled, y_reg_train, y_cls_train, seq_len=cfg['seq_len'])\n",
    "        ds_val = LOBDataset(X_val_scaled, y_reg_val, y_cls_val, seq_len=cfg['seq_len'])\n",
    "        ds_test = LOBDataset(X_test_scaled, y_reg_test, y_cls_test, seq_len=cfg['seq_len'])\n",
    "        \n",
    "        train_loader = DataLoader(ds_train, batch_size=cfg['batch_size'], shuffle=False)\n",
    "        val_loader = DataLoader(ds_val, batch_size=cfg['batch_size'], shuffle=False)\n",
    "        test_loader = DataLoader(ds_test, batch_size=cfg['batch_size'], shuffle=False)\n",
    "        \n",
    "        cnn_model = CNNClassifier(n_features=X_train_scaled.shape[1], n_horizons=len(horizons))\n",
    "        cnn_metrics, cnn_model = train_deep_model(\n",
    "            cnn_model, train_loader, val_loader, test_loader, 'cnn',\n",
    "            epochs=cfg['epochs'], lr=cfg['lr']\n",
    "        )\n",
    "        all_results['cnn'] = cnn_metrics\n",
    "        print(f\"✓ CNN Accuracy h10={cnn_metrics.get('h10_accuracy', 0):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ CNN failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bc10e",
   "metadata": {},
   "source": [
    "## 7. Results Summary & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5dca117",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and all_results:\n",
    "    # Create comprehensive summary table\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"RESULTS SUMMARY - ALL 10 MODELS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Linear models: R²\n",
    "    print(\"\\n[LINEAR MODELS] - Regression R² across horizons:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Model':15s} | h10_R²    h20_R²    h50_R²    h100_R²\")\n",
    "    print(\"-\" * 80)\n",
    "    for model_name in ['ols', 'ridge', 'lasso']:\n",
    "        if model_name in all_results:\n",
    "            metrics = all_results[model_name]\n",
    "            r2_vals = [metrics.get(f'h{h}_r2', 0) for h in horizons]\n",
    "            print(f\"{model_name:15s} | {r2_vals[0]:8.4f} {r2_vals[1]:8.4f} {r2_vals[2]:8.4f} {r2_vals[3]:8.4f}\")\n",
    "    \n",
    "    # Deep models: Classification Accuracy\n",
    "    print(\"\\n[DEEP LEARNING MODELS] - Classification Accuracy across horizons:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Model':20s} | h10_Acc   h20_Acc   h50_Acc   h100_Acc  | h10_F1    h20_F1    h50_F1    h100_F1\")\n",
    "    print(\"-\" * 80)\n",
    "    for model_name in ['mlp', 'lstm', 'cnn', 'deeplob', 'seq2seq', 'transformer', 'temporal_attention']:\n",
    "        if model_name in all_results:\n",
    "            metrics = all_results[model_name]\n",
    "            acc_vals = [metrics.get(f'h{h}_accuracy', 0) for h in horizons]\n",
    "            f1_vals = [metrics.get(f'h{h}_f1_macro', 0) for h in horizons]\n",
    "            print(f\"{model_name:20s} | {acc_vals[0]:8.4f} {acc_vals[1]:8.4f} {acc_vals[2]:8.4f} {acc_vals[3]:8.4f} | {f1_vals[0]:8.4f} {f1_vals[1]:8.4f} {f1_vals[2]:8.4f} {f1_vals[3]:8.4f}\")\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_path = os.path.join(RESULTS_DIR, f'results_all_10_models_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\n✓ Detailed results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "239430a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and all_results:\n",
    "    # Comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # 1. Linear Models R²\n",
    "    ax = axes[0, 0]\n",
    "    for model_name in ['ols', 'ridge', 'lasso']:\n",
    "        if model_name in all_results:\n",
    "            metrics = all_results[model_name]\n",
    "            r2_vals = [metrics.get(f'h{h}_r2', 0) for h in horizons]\n",
    "            ax.plot(horizons, r2_vals, marker='o', label=model_name, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Prediction Horizon (events)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('R²', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Linear Models: Regression Performance', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Deep Models Accuracy\n",
    "    ax = axes[0, 1]\n",
    "    for model_name in ['mlp', 'lstm', 'cnn', 'deeplob', 'seq2seq', 'transformer', 'temporal_attention']:\n",
    "        if model_name in all_results:\n",
    "            metrics = all_results[model_name]\n",
    "            acc_vals = [metrics.get(f'h{h}_accuracy', 0) for h in horizons]\n",
    "            ax.plot(horizons, acc_vals, marker='s', label=model_name, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Prediction Horizon (events)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Deep Learning Models: Classification Accuracy', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. F1 Macro Score (Deep Models)\n",
    "    ax = axes[1, 0]\n",
    "    for model_name in ['mlp', 'lstm', 'cnn', 'deeplob', 'seq2seq', 'transformer', 'temporal_attention']:\n",
    "        if model_name in all_results:\n",
    "            metrics = all_results[model_name]\n",
    "            f1_vals = [metrics.get(f'h{h}_f1_macro', 0) for h in horizons]\n",
    "            ax.plot(horizons, f1_vals, marker='^', label=model_name, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Prediction Horizon (events)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('F1 Score (Macro)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Deep Learning Models: F1-Macro Score', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Best Model at Each Horizon (Accuracy)\n",
    "    ax = axes[1, 1]\n",
    "    best_models = []\n",
    "    best_accs = []\n",
    "    for h in horizons:\n",
    "        best_acc = -1\n",
    "        best_model = None\n",
    "        for model_name in list(all_results.keys()):\n",
    "            acc = all_results[model_name].get(f'h{h}_accuracy', 0)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = model_name\n",
    "        best_models.append(best_model)\n",
    "        best_accs.append(best_acc)\n",
    "    \n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(set(best_models))))\n",
    "    color_map = {model: colors[i] for i, model in enumerate(set(best_models))}\n",
    "    bar_colors = [color_map[m] for m in best_models]\n",
    "    \n",
    "    ax.bar([str(h) for h in horizons], best_accs, color=bar_colors)\n",
    "    ax.set_xlabel('Prediction Horizon', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Best Accuracy', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Best Model Per Horizon', fontsize=12, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add model names on bars\n",
    "    for i, (h, acc, model) in enumerate(zip(horizons, best_accs, best_models)):\n",
    "        ax.text(i, acc + 0.01, model, ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = os.path.join(RESULTS_DIR, f'performance_all_10_models.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Comparison plot saved to {plot_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ea406",
   "metadata": {},
   "source": [
    "## 8. Model Weights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655841c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVED MODEL FILES\n",
      "============================================================\n",
      "No model files saved yet\n"
     ]
    }
   ],
   "source": [
    "# List all saved model files\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVED MODEL FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(MODELS_DIR):\n",
    "    model_files = os.listdir(MODELS_DIR)\n",
    "    if model_files:\n",
    "        print(f\"\\nModels saved in: {MODELS_DIR}\\n\")\n",
    "        for f in sorted(model_files):\n",
    "            fpath = os.path.join(MODELS_DIR, f)\n",
    "            size_mb = os.path.getsize(fpath) / (1024 * 1024)\n",
    "            print(f\"  ✓ {f:40s} ({size_mb:6.2f} MB)\")\n",
    "    else:\n",
    "        print(\"No model files saved yet\")\n",
    "else:\n",
    "    print(f\"Models directory not found: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a37627",
   "metadata": {},
   "source": [
    "## 9. Model Loading & Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c415f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL LOADING & INFERENCE EXAMPLES - ALL 10 MODELS\n",
      "================================================================================\n",
      "\n",
      "[LINEAR MODELS] - Loading & Testing:\n",
      "------------------------------------------------------------\n",
      "\n",
      "[DEEP LEARNING MODELS] - Loading & Testing:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[DEEP LEARNING MODELS] - Loading & Testing:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     35\u001b[39m deep_models_def = {\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmlp\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mMLPClassifier\u001b[49m,\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m: LSTMClassifier,\n\u001b[32m     38\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m'\u001b[39m: CNNClassifier,\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdeeplob\u001b[39m\u001b[33m'\u001b[39m: DeepLOBNet,\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mseq2seq\u001b[39m\u001b[33m'\u001b[39m: Seq2SeqAttention,\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m'\u001b[39m: TransformerClassifier,\n\u001b[32m     42\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtemporal_attention\u001b[39m\u001b[33m'\u001b[39m: TemporalAttentionSeq2Seq,\n\u001b[32m     43\u001b[39m }\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m deep_models_def.keys():\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and test all saved models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL LOADING & INFERENCE EXAMPLES - ALL 10 MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Linear Models\n",
    "print(\"\\n[LINEAR MODELS] - Loading & Testing:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name in ['ols', 'ridge', 'lasso']:\n",
    "    try:\n",
    "        model_path = os.path.join(MODELS_DIR, f'{model_name}_models.pkl')\n",
    "        if os.path.exists(model_path):\n",
    "            with open(model_path, 'rb') as f:\n",
    "                models_loaded = pickle.load(f)\n",
    "            print(f\"✓ {model_name:15s} - {len(models_loaded)} horizon models loaded\")\n",
    "            \n",
    "            # Inference on sample\n",
    "            sample_idx = 0\n",
    "            sample = X_test_scaled[sample_idx:sample_idx+1]\n",
    "            for h, model in list(models_loaded.items())[:1]:  # Test first horizon\n",
    "                if model_name == 'ols':\n",
    "                    sample_const = sm.add_constant(sample)\n",
    "                    pred = model.predict(sample_const)[0]\n",
    "                else:\n",
    "                    pred = model.predict(sample)[0]\n",
    "                print(f\"   Sample prediction (h={h}): Δmid = {pred:8.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {model_name} loading failed: {e}\")\n",
    "\n",
    "# 2. Deep Models\n",
    "print(\"\\n[DEEP LEARNING MODELS] - Loading & Testing:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "deep_models_def = {\n",
    "    'mlp': MLPClassifier,\n",
    "    'lstm': LSTMClassifier,\n",
    "    'cnn': CNNClassifier,\n",
    "    'deeplob': DeepLOBNet,\n",
    "    'seq2seq': Seq2SeqAttention,\n",
    "    'transformer': TransformerClassifier,\n",
    "    'temporal_attention': TemporalAttentionSeq2Seq,\n",
    "}\n",
    "\n",
    "for model_name in deep_models_def.keys():\n",
    "    try:\n",
    "        model_path = os.path.join(MODELS_DIR, f'{model_name}_weights.pt')\n",
    "        if os.path.exists(model_path):\n",
    "            model = deep_models_def[model_name](n_features=X_train_scaled.shape[1], n_horizons=len(horizons))\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"✓ {model_name:20s} - Model loaded and moved to {device}\")\n",
    "            \n",
    "            # Inference on sample sequence/flat\n",
    "            if model_name == 'mlp':\n",
    "                sample = torch.tensor(X_test_scaled[0:1], dtype=torch.float32).to(device)\n",
    "            else:\n",
    "                sample = torch.tensor(X_test_scaled[100:200], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = model(sample)\n",
    "            preds = logits.argmax(dim=-1).cpu().numpy()[0]\n",
    "            \n",
    "            class_names = {0: 'DOWN', 1: 'STAT', 2: 'UP'}\n",
    "            print(f\"   Predictions: {[class_names[p] for p in preds[:2]]} (first 2 horizons)\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {model_name} loading failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd973b",
   "metadata": {},
   "source": [
    "## 10. Metadata & Experiment Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52344b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment metadata\n",
    "metadata = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'device': str(device),\n",
    "    'data': {\n",
    "        'n_total': len(df) if df is not None else 0,\n",
    "        'n_train': len(X_train_scaled) if df is not None else 0,\n",
    "        'n_val': len(X_val_scaled) if df is not None else 0,\n",
    "        'n_test': len(X_test_scaled) if df is not None else 0,\n",
    "        'n_features': X_train_scaled.shape[1] if df is not None else 0,\n",
    "    },\n",
    "    'horizons': horizons,\n",
    "    'models_trained': list(all_results.keys()) if all_results else [],\n",
    "    'feature_names': feature_names if df is not None else [],\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(RESULTS_DIR, 'metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✓ Metadata saved to {metadata_path}\")\n",
    "print(f\"\\n📊 Experiment Summary:\")\n",
    "print(f\"  Training samples: {metadata['data']['n_train']}\")\n",
    "print(f\"  Test samples: {metadata['data']['n_test']}\")\n",
    "print(f\"  Features: {metadata['data']['n_features']}\")\n",
    "print(f\"  Horizons: {metadata['horizons']}\")\n",
    "print(f\"  Models: {len(metadata['models_trained'])} completed\")\n",
    "print(f\"  Device: {metadata['device']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
